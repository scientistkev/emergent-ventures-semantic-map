{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generate Embeddings\n",
        "\n",
        "This notebook generates embeddings for all entries using OpenAI's text-embedding-3-large model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add src to path\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root / \"src\"))\n",
        "\n",
        "from embeddings import generate_embeddings_for_dataset\n",
        "\n",
        "# Set up paths\n",
        "data_path = project_root / \"data\" / \"processed\" / \"cleaned_data.json\"\n",
        "embeddings_path = project_root / \"data\" / \"processed\" / \"embeddings.npy\"\n",
        "\n",
        "print(f\"Loading cleaned data from: {data_path}\")\n",
        "print(f\"Embeddings will be saved to: {embeddings_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load cleaned data\n",
        "with open(data_path, 'r') as f:\n",
        "    cleaned_data = json.load(f)\n",
        "\n",
        "print(f\"Loaded {len(cleaned_data)} entries\")\n",
        "print(f\"\\nExample embedding text:\")\n",
        "print(cleaned_data[0]['embedding_text'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate embeddings\n",
        "embeddings = generate_embeddings_for_dataset(\n",
        "    cleaned_data,\n",
        "    embeddings_path,\n",
        "    text_field=\"embedding_text\",\n",
        "    model=\"text-embedding-3-large\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify embeddings\n",
        "print(f\"Embeddings shape: {embeddings.shape}\")\n",
        "print(f\"Number of entries: {len(cleaned_data)}\")\n",
        "print(f\"Embedding dimension: {embeddings.shape[1]}\")\n",
        "print(f\"\\nEmbedding statistics:\")\n",
        "print(f\"  Mean: {embeddings.mean():.4f}\")\n",
        "print(f\"  Std: {embeddings.std():.4f}\")\n",
        "print(f\"  Min: {embeddings.min():.4f}\")\n",
        "print(f\"  Max: {embeddings.max():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Quick visualization with t-SNE (2D preview)\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Generating 2D t-SNE visualization...\")\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(embeddings) - 1))\n",
        "embeddings_2d = tsne.fit_transform(embeddings)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], alpha=0.6)\n",
        "plt.title(\"2D t-SNE Visualization of Embeddings\")\n",
        "plt.xlabel(\"t-SNE Component 1\")\n",
        "plt.ylabel(\"t-SNE Component 2\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Note: This is just a preview. UMAP will be used for clustering.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
