{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration - EV India 13 Cohort\n",
        "\n",
        "This notebook explores the initial dataset to understand data quality, identify missing fields, and determine normalization needs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data from: /Users/kevinmcpherson/github-projects/emergent-ventures-semantic-map/data/raw/data.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "# Set up paths\n",
        "project_root = Path().resolve().parent\n",
        "data_path = project_root / \"data\" / \"raw\" / \"data.json\"\n",
        "\n",
        "print(f\"Loading data from: {data_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total entries: 18\n",
            "\n",
            "First entry example:\n",
            "{\n",
            "  \"name\": \"Khyathi Komalan\",\n",
            "  \"age\": 19,\n",
            "  \"education\": \"Sophomore at Caltech, majoring in Mathematics\",\n",
            "  \"location\": \"India/USA\",\n",
            "  \"project_name\": \"Category Theory Research\",\n",
            "  \"project_description\": \"Research applying category theory to domains ranging from quantum physics to social relationships.\",\n",
            "  \"domains\": [\n",
            "    \"mathematics\",\n",
            "    \"category theory\",\n",
            "    \"theoretical physics\",\n",
            "    \"complex systems\",\n",
            "    \"social modeling\"\n",
            "  ],\n",
            "  \"category\": \"research\",\n",
            "  \"funding_type\": \"career development\",\n",
            "  \"cohort\": \"EV India 13\",\n",
            "  \"links\": [],\n",
            "  \"embedding_text\": \"Category theory research applied to quantum physics and social relationships by Caltech math student.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "with open(data_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(f\"Total entries: {len(data)}\")\n",
        "print(f\"\\nFirst entry example:\")\n",
        "print(json.dumps(data[0], indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame shape: (18, 12)\n",
            "\n",
            "Columns: ['name', 'age', 'education', 'location', 'project_name', 'project_description', 'domains', 'category', 'funding_type', 'cohort', 'links', 'embedding_text']\n",
            "\n",
            "Data types:\n",
            "name                    object\n",
            "age                    float64\n",
            "education               object\n",
            "location                object\n",
            "project_name            object\n",
            "project_description     object\n",
            "domains                 object\n",
            "category                object\n",
            "funding_type            object\n",
            "cohort                  object\n",
            "links                   object\n",
            "embedding_text          object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Convert to DataFrame for easier analysis\n",
        "df = pd.DataFrame(data)\n",
        "print(f\"DataFrame shape: {df.shape}\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "print(f\"\\nData types:\")\n",
        "print(df.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values per column:\n",
            "name                   0\n",
            "age                    7\n",
            "education              0\n",
            "location               0\n",
            "project_name           0\n",
            "project_description    0\n",
            "domains                0\n",
            "category               0\n",
            "funding_type           0\n",
            "cohort                 0\n",
            "links                  0\n",
            "embedding_text         0\n",
            "dtype: int64\n",
            "\n",
            "Percentage of missing values:\n",
            "name                    0.00\n",
            "age                    38.89\n",
            "education               0.00\n",
            "location                0.00\n",
            "project_name            0.00\n",
            "project_description     0.00\n",
            "domains                 0.00\n",
            "category                0.00\n",
            "funding_type            0.00\n",
            "cohort                  0.00\n",
            "links                   0.00\n",
            "embedding_text          0.00\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "print(f\"\\nPercentage of missing values:\")\n",
        "print((df.isnull().sum() / len(df) * 100).round(2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total unique domains: 46\n",
            "\n",
            "Domain frequency:\n",
            "  hardware: 5\n",
            "  education: 3\n",
            "  automation: 2\n",
            "  ai: 2\n",
            "  career development: 2\n",
            "  energy: 2\n",
            "  healthtech: 2\n",
            "  mathematics: 1\n",
            "  category theory: 1\n",
            "  theoretical physics: 1\n",
            "  complex systems: 1\n",
            "  social modeling: 1\n",
            "  biotech: 1\n",
            "  regenerative medicine: 1\n",
            "  stem cells: 1\n",
            "  neurology: 1\n",
            "  agriculture: 1\n",
            "  sustainability: 1\n",
            "  materials science: 1\n",
            "  climate adaptation: 1\n",
            "  robotics: 1\n",
            "  agritech: 1\n",
            "  hr tech: 1\n",
            "  engineering: 1\n",
            "  evs: 1\n",
            "  battery technology: 1\n",
            "  fintech: 1\n",
            "  civic technology: 1\n",
            "  legal tech: 1\n",
            "  healthcare: 1\n",
            "  medical devices: 1\n",
            "  wearables: 1\n",
            "  labor safety: 1\n",
            "  transportation: 1\n",
            "  open-source: 1\n",
            "  platforms: 1\n",
            "  physics: 1\n",
            "  talent development: 1\n",
            "  aerospace: 1\n",
            "  community building: 1\n",
            "  stem: 1\n",
            "  assistive technology: 1\n",
            "  digital access: 1\n",
            "  smes: 1\n",
            "  business education: 1\n",
            "  learning platforms: 1\n"
          ]
        }
      ],
      "source": [
        "# Analyze domains - collect all unique domains\n",
        "all_domains = []\n",
        "for domains_list in df['domains'].dropna():\n",
        "    if isinstance(domains_list, list):\n",
        "        all_domains.extend([d.lower().strip() for d in domains_list])\n",
        "\n",
        "domain_counts = Counter(all_domains)\n",
        "print(f\"Total unique domains: {len(domain_counts)}\")\n",
        "print(f\"\\nDomain frequency:\")\n",
        "for domain, count in domain_counts.most_common():\n",
        "    print(f\"  {domain}: {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Category distribution:\n",
            "category\n",
            "hardware        6\n",
            "software        4\n",
            "startup         2\n",
            "career          2\n",
            "organization    2\n",
            "research        1\n",
            "education       1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Unique categories: 7\n"
          ]
        }
      ],
      "source": [
        "# Analyze categories\n",
        "print(\"Category distribution:\")\n",
        "print(df['category'].value_counts())\n",
        "print(f\"\\nUnique categories: {df['category'].nunique()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Location distribution:\n",
            "location\n",
            "India           16\n",
            "India/USA        1\n",
            "India/Canada     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Unique locations: 3\n",
            "\n",
            "Locations with '/' (multi-location):\n",
            "                name      location\n",
            "0    Khyathi Komalan     India/USA\n",
            "2  Anushka Punukollu  India/Canada\n"
          ]
        }
      ],
      "source": [
        "# Analyze locations\n",
        "print(\"Location distribution:\")\n",
        "print(df['location'].value_counts())\n",
        "print(f\"\\nUnique locations: {df['location'].nunique()}\")\n",
        "print(f\"\\nLocations with '/' (multi-location):\")\n",
        "multi_location = df[df['location'].str.contains('/', na=False)]\n",
        "print(multi_location[['name', 'location']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Funding type distribution:\n",
            "funding_type\n",
            "project               10\n",
            "career development     4\n",
            "startup                4\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Analyze funding types\n",
        "print(\"Funding type distribution:\")\n",
        "print(df['funding_type'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Age statistics:\n",
            "count    11.000000\n",
            "mean     18.454545\n",
            "std       3.205110\n",
            "min      13.000000\n",
            "25%      17.000000\n",
            "50%      19.000000\n",
            "75%      20.000000\n",
            "max      25.000000\n",
            "Name: age, dtype: float64\n",
            "\n",
            "Entries with age: 11 / 18\n"
          ]
        }
      ],
      "source": [
        "# Analyze age distribution\n",
        "print(\"Age statistics:\")\n",
        "print(df['age'].describe())\n",
        "print(f\"\\nEntries with age: {df['age'].notna().sum()} / {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding text length statistics:\n",
            "count     18.000000\n",
            "mean      58.388889\n",
            "std       14.801188\n",
            "min       35.000000\n",
            "25%       50.250000\n",
            "50%       55.500000\n",
            "75%       65.750000\n",
            "max      101.000000\n",
            "Name: embedding_text_len, dtype: float64\n",
            "\n",
            "Shortest embedding texts:\n",
            "             name                                embedding_text\n",
            "15  Krupal Virani           General career development support.\n",
            "3      Deev Mehta  Autonomous rover enabling automated farming.\n",
            "13     Yash Darji  Building an experimental rocketry community.\n"
          ]
        }
      ],
      "source": [
        "# Check embedding_text quality\n",
        "print(\"Embedding text length statistics:\")\n",
        "df['embedding_text_len'] = df['embedding_text'].str.len()\n",
        "print(df['embedding_text_len'].describe())\n",
        "print(f\"\\nShortest embedding texts:\")\n",
        "print(df.nsmallest(3, 'embedding_text_len')[['name', 'embedding_text']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entries with empty links: 18 / 18\n"
          ]
        }
      ],
      "source": [
        "# Check for empty links\n",
        "empty_links = df[df['links'].apply(lambda x: len(x) == 0 if isinstance(x, list) else True)]\n",
        "print(f\"Entries with empty links: {len(empty_links)} / {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== NORMALIZATION NEEDS ===\n",
            "\n",
            "1. Domains:\n",
            "   - 46 unique domain values need standardization\n",
            "   - Some may need merging (e.g., 'AI' vs 'artificial intelligence')\n",
            "   - Need to handle case variations\n",
            "\n",
            "2. Categories:\n",
            "   - 7 categories appear consistent\n",
            "   - Values: ['research', 'startup', 'hardware', 'software', 'career', 'education', 'organization']\n",
            "\n",
            "3. Locations:\n",
            "   - 3 unique locations\n",
            "   - 2 entries have multiple locations (separated by '/')\n",
            "   - Need to standardize format\n",
            "\n",
            "4. Embedding text:\n",
            "   - Some entries have very short embedding_text\n",
            "   - Should enhance with more context (name + project + domains + category)\n",
            "\n",
            "5. Missing data:\n",
            "   - Age: 7 missing\n",
            "   - Education: 0 missing\n",
            "   - Links: 18 empty\n"
          ]
        }
      ],
      "source": [
        "# Summary of normalization needs\n",
        "print(\"=== NORMALIZATION NEEDS ===\")\n",
        "print(\"\\n1. Domains:\")\n",
        "print(f\"   - {len(domain_counts)} unique domain values need standardization\")\n",
        "print(f\"   - Some may need merging (e.g., 'AI' vs 'artificial intelligence')\")\n",
        "print(f\"   - Need to handle case variations\")\n",
        "\n",
        "print(\"\\n2. Categories:\")\n",
        "print(f\"   - {df['category'].nunique()} categories appear consistent\")\n",
        "print(f\"   - Values: {list(df['category'].unique())}\")\n",
        "\n",
        "print(\"\\n3. Locations:\")\n",
        "print(f\"   - {df['location'].nunique()} unique locations\")\n",
        "print(f\"   - {len(multi_location)} entries have multiple locations (separated by '/')\")\n",
        "print(f\"   - Need to standardize format\")\n",
        "\n",
        "print(\"\\n4. Embedding text:\")\n",
        "print(f\"   - Some entries have very short embedding_text\")\n",
        "print(f\"   - Should enhance with more context (name + project + domains + category)\")\n",
        "\n",
        "print(\"\\n5. Missing data:\")\n",
        "print(f\"   - Age: {df['age'].isna().sum()} missing\")\n",
        "print(f\"   - Education: {df['education'].isna().sum()} missing\")\n",
        "print(f\"   - Links: {len(empty_links)} empty\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
