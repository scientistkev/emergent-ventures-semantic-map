{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration - EV India 13 Cohort\n",
        "\n",
        "This notebook explores the initial dataset to understand data quality, identify missing fields, and determine normalization needs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "# Set up paths\n",
        "project_root = Path().resolve().parent\n",
        "data_path = project_root / \"data\" / \"raw\" / \"data.json\"\n",
        "\n",
        "print(f\"Loading data from: {data_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "with open(data_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(f\"Total entries: {len(data)}\")\n",
        "print(f\"\\nFirst entry example:\")\n",
        "print(json.dumps(data[0], indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to DataFrame for easier analysis\n",
        "df = pd.DataFrame(data)\n",
        "print(f\"DataFrame shape: {df.shape}\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "print(f\"\\nData types:\")\n",
        "print(df.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "print(f\"\\nPercentage of missing values:\")\n",
        "print((df.isnull().sum() / len(df) * 100).round(2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze domains - collect all unique domains\n",
        "all_domains = []\n",
        "for domains_list in df['domains'].dropna():\n",
        "    if isinstance(domains_list, list):\n",
        "        all_domains.extend([d.lower().strip() for d in domains_list])\n",
        "\n",
        "domain_counts = Counter(all_domains)\n",
        "print(f\"Total unique domains: {len(domain_counts)}\")\n",
        "print(f\"\\nDomain frequency:\")\n",
        "for domain, count in domain_counts.most_common():\n",
        "    print(f\"  {domain}: {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze categories\n",
        "print(\"Category distribution:\")\n",
        "print(df['category'].value_counts())\n",
        "print(f\"\\nUnique categories: {df['category'].nunique()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze locations\n",
        "print(\"Location distribution:\")\n",
        "print(df['location'].value_counts())\n",
        "print(f\"\\nUnique locations: {df['location'].nunique()}\")\n",
        "print(f\"\\nLocations with '/' (multi-location):\")\n",
        "multi_location = df[df['location'].str.contains('/', na=False)]\n",
        "print(multi_location[['name', 'location']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze funding types\n",
        "print(\"Funding type distribution:\")\n",
        "print(df['funding_type'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze age distribution\n",
        "print(\"Age statistics:\")\n",
        "print(df['age'].describe())\n",
        "print(f\"\\nEntries with age: {df['age'].notna().sum()} / {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check embedding_text quality\n",
        "print(\"Embedding text length statistics:\")\n",
        "df['embedding_text_len'] = df['embedding_text'].str.len()\n",
        "print(df['embedding_text_len'].describe())\n",
        "print(f\"\\nShortest embedding texts:\")\n",
        "print(df.nsmallest(3, 'embedding_text_len')[['name', 'embedding_text']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for empty links\n",
        "empty_links = df[df['links'].apply(lambda x: len(x) == 0 if isinstance(x, list) else True)]\n",
        "print(f\"Entries with empty links: {len(empty_links)} / {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary of normalization needs\n",
        "print(\"=== NORMALIZATION NEEDS ===\")\n",
        "print(\"\\n1. Domains:\")\n",
        "print(f\"   - {len(domain_counts)} unique domain values need standardization\")\n",
        "print(f\"   - Some may need merging (e.g., 'AI' vs 'artificial intelligence')\")\n",
        "print(f\"   - Need to handle case variations\")\n",
        "\n",
        "print(\"\\n2. Categories:\")\n",
        "print(f\"   - {df['category'].nunique()} categories appear consistent\")\n",
        "print(f\"   - Values: {list(df['category'].unique())}\")\n",
        "\n",
        "print(\"\\n3. Locations:\")\n",
        "print(f\"   - {df['location'].nunique()} unique locations\")\n",
        "print(f\"   - {len(multi_location)} entries have multiple locations (separated by '/')\")\n",
        "print(f\"   - Need to standardize format\")\n",
        "\n",
        "print(\"\\n4. Embedding text:\")\n",
        "print(f\"   - Some entries have very short embedding_text\")\n",
        "print(f\"   - Should enhance with more context (name + project + domains + category)\")\n",
        "\n",
        "print(\"\\n5. Missing data:\")\n",
        "print(f\"   - Age: {df['age'].isna().sum()} missing\")\n",
        "print(f\"   - Education: {df['education'].isna().sum()} missing\")\n",
        "print(f\"   - Links: {len(empty_links)} empty\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
