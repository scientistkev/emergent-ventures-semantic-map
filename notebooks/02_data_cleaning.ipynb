{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Cleaning & Normalization\n",
        "\n",
        "This notebook cleans and normalizes the EV India 13 dataset, creating controlled vocabularies and enhancing embedding text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data from: /Users/kevinmcpherson/github-projects/emergent-ventures-semantic-map/data/raw/data.json\n",
            "Output will be saved to: /Users/kevinmcpherson/github-projects/emergent-ventures-semantic-map/data/processed/cleaned_data.json\n",
            "Vocabularies will be saved to: /Users/kevinmcpherson/github-projects/emergent-ventures-semantic-map/data/vocabularies\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add src to path\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root / \"src\"))\n",
        "\n",
        "from data_cleaning import clean_dataset\n",
        "\n",
        "# Set up paths\n",
        "data_path = project_root / \"data\" / \"raw\" / \"data.json\"\n",
        "output_path = project_root / \"data\" / \"processed\" / \"cleaned_data.json\"\n",
        "vocab_dir = project_root / \"data\" / \"vocabularies\"\n",
        "\n",
        "print(f\"Loading data from: {data_path}\")\n",
        "print(f\"Output will be saved to: {output_path}\")\n",
        "print(f\"Vocabularies will be saved to: {vocab_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 18 entries\n",
            "\n",
            "Example raw entry:\n",
            "{\n",
            "  \"name\": \"Khyathi Komalan\",\n",
            "  \"age\": 19,\n",
            "  \"education\": \"Sophomore at Caltech, majoring in Mathematics\",\n",
            "  \"location\": \"India/USA\",\n",
            "  \"project_name\": \"Category Theory Research\",\n",
            "  \"project_description\": \"Research applying category theory to domains ranging from quantum physics to social relationships.\",\n",
            "  \"domains\": [\n",
            "    \"mathematics\",\n",
            "    \"category theory\",\n",
            "    \"theoretical physics\",\n",
            "    \"complex systems\",\n",
            "    \"social modeling\"\n",
            "  ],\n",
            "  \"category\": \"research\",\n",
            "  \"funding_type\": \"career development\",\n",
            "  \"cohort\": \"EV India 13\",\n",
            "  \"links\": [],\n",
            "  \"embedding_text\": \"Category theory research applied to quantum physics and social relationships by Caltech math student.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Load raw data\n",
        "with open(data_path, 'r') as f:\n",
        "    raw_data = json.load(f)\n",
        "\n",
        "print(f\"Loaded {len(raw_data)} entries\")\n",
        "print(f\"\\nExample raw entry:\")\n",
        "print(json.dumps(raw_data[0], indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned 18 entries\n",
            "\n",
            "Created vocabularies:\n",
            "  - 29 canonical domains\n",
            "  - 7 categories\n",
            "  - 1 locations\n"
          ]
        }
      ],
      "source": [
        "# Clean dataset\n",
        "cleaned_data, vocabularies = clean_dataset(raw_data, vocab_dir)\n",
        "\n",
        "print(f\"Cleaned {len(cleaned_data)} entries\")\n",
        "print(f\"\\nCreated vocabularies:\")\n",
        "print(f\"  - {len(vocabularies['domains'])} canonical domains\")\n",
        "print(f\"  - {len(vocabularies['categories'])} categories\")\n",
        "print(f\"  - {len(vocabularies['locations'])} locations\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example cleaned entry:\n",
            "{\n",
            "  \"name\": \"Khyathi Komalan\",\n",
            "  \"age\": 19,\n",
            "  \"education\": \"Sophomore at Caltech, majoring in Mathematics\",\n",
            "  \"location\": \"India/USA\",\n",
            "  \"project_name\": \"Category Theory Research\",\n",
            "  \"project_description\": \"Research applying category theory to domains ranging from quantum physics to social relationships.\",\n",
            "  \"domains\": [\n",
            "    \"mathematics\",\n",
            "    \"category theory\",\n",
            "    \"theoretical physics\",\n",
            "    \"complex systems\",\n",
            "    \"social modeling\"\n",
            "  ],\n",
            "  \"category\": \"research\",\n",
            "  \"funding_type\": \"career development\",\n",
            "  \"cohort\": \"EV India 13\",\n",
            "  \"links\": [],\n",
            "  \"embedding_text\": \"Khyathi Komalan. works on Category Theory Research. : Research applying category theory to domains ranging from quantum physics to social relationships.. Domains: mathematics, category theory, theoretical physics, complex systems, social modeling. Category: research.\",\n",
            "  \"domains_normalized\": [\n",
            "    \"mathematics\",\n",
            "    \"physics\",\n",
            "    \"complex systems\",\n",
            "    \"social modeling\"\n",
            "  ],\n",
            "  \"location_normalized\": \"India\",\n",
            "  \"category_normalized\": \"research\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Show example cleaned entry\n",
        "print(\"Example cleaned entry:\")\n",
        "print(json.dumps(cleaned_data[0], indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== DOMAINS ===\n",
            "  - aerospace\n",
            "  - agriculture\n",
            "  - artificial intelligence\n",
            "  - automation\n",
            "  - biotechnology\n",
            "  - business\n",
            "  - career development\n",
            "  - civic technology\n",
            "  - climate adaptation\n",
            "  - community building\n",
            "  - complex systems\n",
            "  - education\n",
            "  - energy\n",
            "  - engineering\n",
            "  - financial technology\n",
            "  - hardware\n",
            "  - healthcare\n",
            "  - human resources\n",
            "  - legal technology\n",
            "  - materials science\n",
            "  ... and 9 more\n",
            "\n",
            "=== CATEGORIES ===\n",
            "  - career\n",
            "  - education\n",
            "  - hardware\n",
            "  - organization\n",
            "  - research\n",
            "  - software\n",
            "  - startup\n",
            "\n",
            "=== LOCATIONS ===\n",
            "  - India\n"
          ]
        }
      ],
      "source": [
        "# Show vocabularies\n",
        "print(\"=== DOMAINS ===\")\n",
        "for domain in vocabularies['domains'][:20]:  # Show first 20\n",
        "    print(f\"  - {domain}\")\n",
        "if len(vocabularies['domains']) > 20:\n",
        "    print(f\"  ... and {len(vocabularies['domains']) - 20} more\")\n",
        "\n",
        "print(f\"\\n=== CATEGORIES ===\")\n",
        "for cat in vocabularies['categories']:\n",
        "    print(f\"  - {cat}\")\n",
        "\n",
        "print(f\"\\n=== LOCATIONS ===\")\n",
        "for loc in vocabularies['locations']:\n",
        "    print(f\"  - {loc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Domain normalization examples:\n",
            "\n",
            "Khyathi Komalan:\n",
            "  Original: ['mathematics', 'category theory', 'theoretical physics', 'complex systems', 'social modeling']\n",
            "  Normalized: ['mathematics', 'physics', 'complex systems', 'social modeling']\n",
            "  Enhanced embedding_text: Khyathi Komalan. works on Category Theory Research. : Research applying category theory to domains r...\n",
            "\n",
            "Soumil Nema:\n",
            "  Original: ['biotech', 'regenerative medicine', 'stem cells', 'neurology']\n",
            "  Normalized: ['biotechnology', 'healthcare']\n",
            "  Enhanced embedding_text: Soumil Nema. works on Stem Cell Therapies for Neurological Disorders. : Developing stem cell therapi...\n",
            "\n",
            "Anushka Punukollu:\n",
            "  Original: ['agriculture', 'sustainability', 'materials science', 'climate adaptation']\n",
            "  Normalized: ['agriculture', 'sustainability', 'materials science', 'climate adaptation']\n",
            "  Enhanced embedding_text: Anushka Punukollu. works on SucroSoil. : Repurposing sugarcane waste into hydrogels to combat soil e...\n",
            "\n",
            "Deev Mehta:\n",
            "  Original: ['robotics', 'agritech', 'automation']\n",
            "  Normalized: ['robotics', 'agriculture', 'automation']\n",
            "  Enhanced embedding_text: Deev Mehta. works on Autonomous Farming Rover. : Developing a rover to make farming autonomous.. Dom...\n",
            "\n",
            "Adithya Sakaray, Steve Aldrin, and Aadhithya D:\n",
            "  Original: ['AI', 'HR tech', 'automation']\n",
            "  Normalized: ['artificial intelligence', 'human resources', 'automation']\n",
            "  Enhanced embedding_text: Adithya Sakaray, Steve Aldrin, and Aadhithya D. works on Recruitr AI. : Automating video interviews ...\n"
          ]
        }
      ],
      "source": [
        "# Compare original vs normalized domains for a few entries\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(cleaned_data)\n",
        "\n",
        "print(\"Domain normalization examples:\")\n",
        "for idx, row in df.head(5).iterrows():\n",
        "    print(f\"\\n{row['name']}:\")\n",
        "    print(f\"  Original: {row.get('domains', [])}\")\n",
        "    print(f\"  Normalized: {row.get('domains_normalized', [])}\")\n",
        "    print(f\"  Enhanced embedding_text: {row['embedding_text'][:100]}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved cleaned data to: /Users/kevinmcpherson/github-projects/emergent-ventures-semantic-map/data/processed/cleaned_data.json\n",
            "Saved vocabularies to: /Users/kevinmcpherson/github-projects/emergent-ventures-semantic-map/data/vocabularies\n"
          ]
        }
      ],
      "source": [
        "# Save cleaned data\n",
        "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "with open(output_path, 'w') as f:\n",
        "    json.dump(cleaned_data, f, indent=2)\n",
        "\n",
        "print(f\"Saved cleaned data to: {output_path}\")\n",
        "print(f\"Saved vocabularies to: {vocab_dir}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
