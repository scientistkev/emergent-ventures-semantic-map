{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clustering Analysis\n",
        "\n",
        "This notebook performs clustering analysis using UMAP for dimensionality reduction and HDBSCAN/K-means for clustering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add src to path\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root / \"src\"))\n",
        "\n",
        "from clustering import perform_clustering_analysis\n",
        "\n",
        "# Set up paths\n",
        "data_path = project_root / \"data\" / \"processed\" / \"cleaned_data.json\"\n",
        "embeddings_path = project_root / \"data\" / \"processed\" / \"embeddings.npy\"\n",
        "output_dir = project_root / \"data\" / \"processed\"\n",
        "\n",
        "print(f\"Loading data from: {data_path}\")\n",
        "print(f\"Loading embeddings from: {embeddings_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data and embeddings\n",
        "with open(data_path, 'r') as f:\n",
        "    cleaned_data = json.load(f)\n",
        "\n",
        "embeddings = np.load(embeddings_path)\n",
        "\n",
        "print(f\"Loaded {len(cleaned_data)} entries\")\n",
        "print(f\"Embeddings shape: {embeddings.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform clustering analysis (both methods)\n",
        "results = perform_clustering_analysis(\n",
        "    cleaned_data,\n",
        "    embeddings,\n",
        "    method=\"both\",\n",
        "    output_dir=output_dir\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display HDBSCAN results\n",
        "if 'hdbscan' in results:\n",
        "    print(\"=== HDBSCAN CLUSTERING RESULTS ===\")\n",
        "    hdbscan_analysis = results['hdbscan']['analysis']\n",
        "    \n",
        "    print(f\"\\nNumber of clusters: {hdbscan_analysis['n_clusters']}\")\n",
        "    print(f\"Noise points: {hdbscan_analysis['n_noise']}\")\n",
        "    \n",
        "    print(\"\\nCluster summaries:\")\n",
        "    for summary in hdbscan_analysis['cluster_summaries']:\n",
        "        print(f\"\\nCluster {summary['cluster_id']} ({summary['size']} entries):\")\n",
        "        print(f\"  Top domains: {list(summary['top_domains'].keys())}\")\n",
        "        print(f\"  Top categories: {list(summary['top_categories'].keys())}\")\n",
        "        print(f\"  Names: {', '.join(summary['names'][:5])}\")\n",
        "        if len(summary['names']) > 5:\n",
        "            print(f\"  ... and {len(summary['names']) - 5} more\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display K-means results\n",
        "if 'kmeans' in results:\n",
        "    print(\"=== K-MEANS CLUSTERING RESULTS ===\")\n",
        "    kmeans_analysis = results['kmeans']['analysis']\n",
        "    optimal_k = results['kmeans']['optimal_k']\n",
        "    \n",
        "    print(f\"\\nOptimal k: {optimal_k}\")\n",
        "    print(f\"Number of clusters: {kmeans_analysis['n_clusters']}\")\n",
        "    \n",
        "    print(\"\\nCluster summaries:\")\n",
        "    for summary in kmeans_analysis['cluster_summaries']:\n",
        "        print(f\"\\nCluster {summary['cluster_id']} ({summary['size']} entries):\")\n",
        "        print(f\"  Top domains: {list(summary['top_domains'].keys())}\")\n",
        "        print(f\"  Top categories: {list(summary['top_categories'].keys())}\")\n",
        "        print(f\"  Names: {', '.join(summary['names'][:5])}\")\n",
        "        if len(summary['names']) > 5:\n",
        "            print(f\"  ... and {len(summary['names']) - 5} more\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add cluster assignments to data and save\n",
        "import json\n",
        "\n",
        "# Use K-means results (or HDBSCAN if preferred)\n",
        "if 'kmeans' in results:\n",
        "    cluster_labels = results['kmeans']['labels']\n",
        "    method = 'kmeans'\n",
        "else:\n",
        "    cluster_labels = results['hdbscan']['labels']\n",
        "    method = 'hdbscan'\n",
        "\n",
        "# Add cluster assignments\n",
        "for i, entry in enumerate(cleaned_data):\n",
        "    entry[f'cluster_{method}'] = int(cluster_labels[i])\n",
        "\n",
        "# Save updated data\n",
        "output_path = project_root / \"data\" / \"processed\" / \"cleaned_data.json\"\n",
        "with open(output_path, 'w') as f:\n",
        "    json.dump(cleaned_data, f, indent=2)\n",
        "\n",
        "print(f\"Saved data with cluster assignments to: {output_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
